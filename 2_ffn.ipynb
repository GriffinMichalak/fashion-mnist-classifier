{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7d70712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from cnn import *\n",
    "from ffn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0079539",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIM = 10\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "IMAGE_HEIGHT = 28\n",
    "IMAGE_WIDTH = 28\n",
    "INPUT_DIM = IMAGE_HEIGHT * IMAGE_WIDTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "803598fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/griffinmichalak/Desktop/code/fall25/intro-ai/PA3-1/venv/lib/python3.13/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([                            # Use transforms to convert images to tensors and normalize them\n",
    "    transforms.ToTensor(),                                  # convert images to tensor\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])             # Common method for grayscale images\n",
    "])\n",
    "\n",
    "batch_size = 64 # 32â€“128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a7a0662",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.FashionMNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.FashionMNIST(root=\"data\", train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44d354f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedforward_net = FF_Net()\n",
    "# conv_net = Conv_Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # loss function\n",
    "\n",
    "optimizer_ffn = optim.Adam(feedforward_net.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c141ee1e",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ba340e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 456.7771426588297\n",
      "Training loss: 340.21709564328194\n",
      "Training loss: 303.87860518693924\n",
      "Training loss: 280.1514623761177\n",
      "Training loss: 260.28709606826305\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "num_epochs_ffn = NUM_EPOCHS\n",
    "\n",
    "for epoch in range(num_epochs_ffn):  # loop over the dataset multiple times\n",
    "    running_loss_ffn = 0.0\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Flatten inputs for ffn\n",
    "        ''' flattening within FF_Net.forward() '''\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer_ffn.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = feedforward_net(inputs)  # forward pass happens here\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_ffn.step()\n",
    "        running_loss_ffn += loss.item()\n",
    "\n",
    "    print(f\"Training loss: {running_loss_ffn}\")\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "torch.save(feedforward_net.state_dict(), 'ffn.pth')  # Saves model file (upload with submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86c867f",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41e345a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for feedforward network:  0.8682\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "PART 6:\n",
    "Evalute your models! Accuracy should be greater or equal to 80% for both models.\n",
    "\n",
    "Code to load saved weights commented out below - may be useful for debugging.\n",
    "\n",
    "'''\n",
    "\n",
    "feedforward_net.load_state_dict(torch.load('ffn.pth'))\n",
    "# conv_net.load_state_dict(torch.load('cnn.pth'))\n",
    "\n",
    "correct_ffn = 0\n",
    "total_ffn = 0\n",
    "\n",
    "with torch.no_grad():           # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    for data in testloader:\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = feedforward_net(images)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            # collect the correct predictions for each class\n",
    "            for label, prediction in zip(labels, predictions):\n",
    "                if label == prediction:\n",
    "                    correct_ffn = correct_ffn + 1\n",
    "                total_ffn = total_ffn + 1\n",
    "\n",
    "print('Accuracy for feedforward network: ', correct_ffn/total_ffn)\n",
    "# print('Accuracy for convolutional network: ', correct_cnn/total_cnn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
